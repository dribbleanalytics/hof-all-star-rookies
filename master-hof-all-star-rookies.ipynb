{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import neighbors\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from operator import itemgetter\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the datasets\n",
    "\n",
    "dfHistorical = pd.read_csv('historical-rookies.csv')\n",
    "dfRookies = pd.read_csv('2017-rookies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the historical dataset\n",
    "\n",
    "dfHistorical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the rookies dataset\n",
    "\n",
    "dfRookies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare rookie dataset for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare rookies dataframe to be plugged into machine learning models by skipping columns that aren't parameters in the model\n",
    "\n",
    "rookieTest = dfRookies[['G', 'MPG', 'FG/G', 'FGA/G', '2P%', '3P%', 'FT%', 'TRB/G', 'AST/G', 'STL/G', 'BLK/G', 'TOV/G', 'PF/G',\n",
    "                        'TS%', '3PAr', 'FTr']]\n",
    "\n",
    "rookieNames = dfRookies.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating data splits for HOF models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(dfHistorical, test_size = 0.25, random_state = 0)\n",
    "\n",
    "xtrain = train[['G', 'MPG', 'FG/G', 'FGA/G', '2P%', '3P%', 'FT%', 'TRB/G', 'AST/G', 'STL/G', 'BLK/G', 'TOV/G', 'PF/G',\n",
    "                'TS%', '3PAr', 'FTr']]\n",
    "ytrain = train[['Hall of Fame']]\n",
    " \n",
    "xtest = test[['G', 'MPG', 'FG/G', 'FGA/G', '2P%', '3P%', 'FT%', 'TRB/G', 'AST/G', 'STL/G', 'BLK/G', 'TOV/G', 'PF/G',\n",
    "              'TS%', '3PAr', 'FTr']]\n",
    "ytest = test[['Hall of Fame']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create models and confusion matrices for HOF models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel='rbf', gamma=1e-4, C=10, probability = True)\n",
    "svc.fit(xtrain, ytrain.values.ravel())\n",
    "\n",
    "y_svc = svc.predict(xtest)\n",
    "\n",
    "print(\"Accuracy score: %.3f\" % metrics.accuracy_score(ytest, y_svc))\n",
    "\n",
    "proba = svc.predict_proba(xtest)\n",
    "print(\"Log loss: %.3f\" % metrics.log_loss(ytest, proba))\n",
    "\n",
    "posProb = proba[:, 1]\n",
    "print(\"Area under ROC curve: %.3f\" % metrics.roc_auc_score(ytest, posProb))\n",
    "\n",
    "fprSVC, tprSVC, thresholdSVC = metrics.roc_curve(ytest, posProb)\n",
    "roc_aucSVC = metrics.auc(fprSVC, tprSVC)\n",
    "\n",
    "cvScoreSVC = cross_val_score(svc, xtest, ytest.values.ravel(), cv = 3, scoring = 'accuracy')\n",
    "print(\"Accuracy (cross validation score): %0.2f (+/- %0.2f)\" % (cvScoreSVC.mean(), cvScoreSVC.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(ytest, y_svc)\n",
    "\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "svcHofCM, ax = plt.subplots()\n",
    "\n",
    "sns.heatmap(cm, annot=True, ax = ax, linewidth = 2)\n",
    "\n",
    "ax.set_xlabel(\"Predicted\")\n",
    "ax.set_ylabel(\"Actual\")\n",
    "\n",
    "labels = [\"Not HOF\", \"HOF\"]\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_yticklabels(labels)\n",
    "\n",
    "svcHofCM.suptitle(\"SVC Confusion Matrix\", weight = 'bold', size = 18, y = 1.04, x = .45)\n",
    "ax.set_title(\"http://dribbleanalytics.blogspot.com\", size = 14, fontname = 'Rockwell', y = 1.02)\n",
    "\n",
    "svcHofCM.savefig('svc-hof-cm.png', dpi = 400, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state = 999, n_estimators = 100, criterion = 'gini')\n",
    "rfPred = rf.fit(xtrain, ytrain.values.ravel())\n",
    "y_rf = rfPred.predict(xtest)\n",
    "\n",
    "print(\"Accuracy score: %.3f\" % metrics.accuracy_score(ytest, y_rf))\n",
    "\n",
    "proba = rf.predict_proba(xtest)\n",
    "print(\"Log loss: %.3f\" % metrics.log_loss(ytest, proba))\n",
    "\n",
    "posProb = proba[:, 1]\n",
    "print(\"Area under ROC curve: %.3f\" % metrics.roc_auc_score(ytest, posProb))\n",
    "\n",
    "fprRF, tprRF, thresholdRF = metrics.roc_curve(ytest, posProb)\n",
    "roc_aucRF = metrics.auc(fprRF, tprRF)\n",
    "\n",
    "cvScoreRF = cross_val_score(rf, xtest, ytest.values.ravel(), cv = 3, scoring = 'accuracy')\n",
    "print(\"Accuracy (cross validation score): %0.2f (+/- %0.2f)\" % (cvScoreRF.mean(), cvScoreRF.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(ytest, y_rf)\n",
    "\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "rfHofCM, ax = plt.subplots()\n",
    "\n",
    "sns.heatmap(cm, annot=True, ax = ax, linewidth = 2)\n",
    "\n",
    "ax.set_xlabel(\"Predicted\")\n",
    "ax.set_ylabel(\"Actual\")\n",
    "\n",
    "labels = [\"Not HOF\", \"HOF\"]\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_yticklabels(labels)\n",
    "\n",
    "rfHofCM.suptitle(\"RF Confusion Matrix\", weight = 'bold', size = 18, y = 1.04, x = .45)\n",
    "ax.set_title(\"http://dribbleanalytics.blogspot.com\", size = 14, fontname = 'Rockwell', y = 1.02)\n",
    "\n",
    "rfHofCM.savefig('rf-hof-cm.png', dpi = 400, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors = 8, weights = 'uniform')\n",
    "knn.fit(xtrain, ytrain.values.ravel())\n",
    "\n",
    "y_knn = knn.predict(xtest)\n",
    "\n",
    "print(\"Accuracy score: %.3f\" % metrics.accuracy_score(ytest, y_knn))\n",
    "\n",
    "proba = knn.predict_proba(xtest)\n",
    "print(\"Log loss: %.3f\" % metrics.log_loss(ytest, proba))\n",
    "\n",
    "posProb = proba[:, 1]\n",
    "print(\"Area under ROC curve: %.3f\" % metrics.roc_auc_score(ytest, posProb))\n",
    "\n",
    "fprKNN, tprKNN, thresholdKNN = metrics.roc_curve(ytest, posProb)\n",
    "roc_aucKNN = metrics.auc(fprKNN, tprKNN)\n",
    "\n",
    "cvScoreKNN = cross_val_score(knn, xtest, ytest.values.ravel(), cv = 3, scoring = 'accuracy')\n",
    "print(\"Accuracy (cross validation score): %0.2f (+/- %0.2f)\" % (cvScoreKNN.mean(), cvScoreKNN.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(ytest, y_knn)\n",
    "\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "knnHofCM, ax = plt.subplots()\n",
    "\n",
    "sns.heatmap(cm, annot=True, ax = ax, linewidth = 2)\n",
    "\n",
    "ax.set_xlabel(\"Predicted\")\n",
    "ax.set_ylabel(\"Actual\")\n",
    "\n",
    "labels = [\"Not HOF\", \"HOF\"]\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_yticklabels(labels)\n",
    "\n",
    "knnHofCM.suptitle(\"KNN Confusion Matrix\", weight = 'bold', size = 18, y = 1.04, x = .45)\n",
    "ax.set_title(\"http://dribbleanalytics.blogspot.com\", size = 14, fontname = 'Rockwell', y = 1.02)\n",
    "\n",
    "knnHofCM.savefig('knn-hof-cm.png', dpi = 400, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn = MLPClassifier(\n",
    "    solver='lbfgs',\n",
    "    hidden_layer_sizes=100,\n",
    "    max_iter=10000,\n",
    "    shuffle=False,\n",
    "    random_state=0,\n",
    "    activation='identity')\n",
    "\n",
    "dnn.fit(xtrain, ytrain.values.ravel())\n",
    "\n",
    "y_dnn = dnn.predict(xtest)\n",
    "\n",
    "print(\"Accuracy score: %.3f\" % metrics.accuracy_score(ytest, y_dnn))\n",
    "\n",
    "proba = dnn.predict_proba(xtest)\n",
    "print(\"Log loss: %.3f\" % metrics.log_loss(ytest, proba))\n",
    "\n",
    "posProb = proba[:, 1]\n",
    "print(\"Area under ROC curve: %.3f\" % metrics.roc_auc_score(ytest, posProb))\n",
    "\n",
    "fprDNN, tprDNN, thresholdDNN = metrics.roc_curve(ytest, posProb)\n",
    "roc_aucDNN = metrics.auc(fprDNN, tprDNN)\n",
    "\n",
    "cvScoreDNN = cross_val_score(dnn, xtest, ytest.values.ravel(), cv = 3, scoring = 'accuracy')\n",
    "print(\"Accuracy (cross validation score): %0.2f (+/- %0.2f)\" % (cvScoreDNN.mean(), cvScoreDNN.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(ytest, y_dnn)\n",
    "\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "dnnHofCM, ax = plt.subplots()\n",
    "\n",
    "sns.heatmap(cm, annot=True, ax = ax, linewidth = 2)\n",
    "\n",
    "ax.set_xlabel(\"Predicted\")\n",
    "ax.set_ylabel(\"Actual\")\n",
    "\n",
    "labels = [\"Not HOF\", \"HOF\"]\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_yticklabels(labels)\n",
    "\n",
    "dnnHofCM.suptitle(\"DNN Confusion Matrix\", weight = 'bold', size = 18, y = 1.04, x = .45)\n",
    "ax.set_title(\"http://dribbleanalytics.blogspot.com\", size = 14, fontname = 'Rockwell', y = 1.02)\n",
    "\n",
    "dnnHofCM.savefig('dnn-hof-cm.png', dpi = 400, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomized search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC\n",
    "\n",
    "C = [int(x) for x in np.linspace(start = 1, stop = 100, num = 10)]\n",
    "\n",
    "kernel = ['rbf', 'linear']\n",
    "\n",
    "gamma = [float(x) for x in np.linspace(start = 1e-5, stop = 10, num = 10)]\n",
    "\n",
    "random_grid = {'C': C,\n",
    "               'kernel': kernel,\n",
    "               'gamma': gamma}\n",
    "\n",
    "svc_random = RandomizedSearchCV(estimator = svc, param_distributions = random_grid, n_iter = 25, cv = 3, \n",
    "                                verbose=2, random_state=42, n_jobs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_random.fit(xtrain, ytrain.values.ravel())\n",
    "\n",
    "y_svcrand = svc_random.predict(xtest)\n",
    "\n",
    "searchScore = metrics.accuracy_score(ytest, y_svcrand)\n",
    "nonSearchScore = metrics.accuracy_score(ytest, y_svc)\n",
    "improvement = (searchScore - nonSearchScore) / nonSearchScore\n",
    "\n",
    "print(\"Percent improvement: %.5f\" % improvement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 500, num = 10)]\n",
    "\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "bootstrap = [True, False]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 25, cv = 3, \n",
    "                               verbose=2, random_state=42, n_jobs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.fit(xtrain, ytrain.values.ravel())\n",
    "\n",
    "y_rfrand = rf_random.predict(xtest)\n",
    "\n",
    "searchScore = metrics.accuracy_score(ytest, y_rfrand)\n",
    "nonSearchScore = metrics.accuracy_score(ytest, y_rf)\n",
    "improvement = (searchScore - nonSearchScore) / nonSearchScore\n",
    "\n",
    "print(\"Percent improvement: %.5f\" % improvement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "\n",
    "n_neighbors = [int(x) for x in np.linspace(1, 50, num = 10)]\n",
    "\n",
    "weights = ['distance', 'uniform']\n",
    "\n",
    "random_grid = {'n_neighbors': n_neighbors,\n",
    "               'weights': weights}\n",
    "\n",
    "knn_random = RandomizedSearchCV(estimator = knn, param_distributions = random_grid, n_iter = 25, cv = 3, \n",
    "                               verbose=2, random_state=42, n_jobs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_random.fit(xtrain, ytrain.values.ravel())\n",
    "\n",
    "y_knnrand = knn_random.predict(xtest)\n",
    "\n",
    "searchScore = metrics.accuracy_score(ytest, y_knnrand)\n",
    "nonSearchScore = metrics.accuracy_score(ytest, y_knn)\n",
    "improvement = (searchScore - nonSearchScore) / nonSearchScore\n",
    "\n",
    "print(\"Percent improvement: %.5f\" % improvement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNN\n",
    "\n",
    "hidden_layers = [int(x) for x in np.linspace(start = 10, stop = 500, num = 10)]\n",
    "\n",
    "activation = ['identity', 'logistic', 'relu', 'tanh']\n",
    "\n",
    "solver = ['lbfgs', 'adam', 'sgd']\n",
    "\n",
    "random_grid = {'hidden_layers': hidden_layers,\n",
    "               'activation': activation,\n",
    "               'solver': solver}\n",
    "\n",
    "dnn_random = RandomizedSearchCV(estimator = dnn, param_distributions = random_grid, n_iter = 25, cv = 3, \n",
    "                               verbose=2, random_state=42, n_jobs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_random.fit(xtrain, ytrain.values.ravel())\n",
    "\n",
    "y_dnnrand = dnn_random.predict(xtest)\n",
    "\n",
    "searchScore = metrics.accuracy_score(ytest, y_dnnrand)\n",
    "nonSearchScore = metrics.accuracy_score(ytest, y_dnn)\n",
    "improvement = (searchScore - nonSearchScore) / nonSearchScore\n",
    "\n",
    "print(\"Percent improvement: %.5f\" % improvement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC curves for HOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "rocHOF, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, sharey = True, sharex = True)\n",
    "\n",
    "ax1.plot(fprSVC, tprSVC, label = 'ROC curve')\n",
    "ax1.plot([0, 1], [0, 1], linestyle = '--', label = 'Reference line')\n",
    "ax1.set_title(\"SVC: %.2f\" % roc_aucSVC, size = 21, x = .485, ha = 'center')\n",
    "\n",
    "ax2.plot(fprRF, tprRF)\n",
    "ax2.plot([0, 1], [0, 1], linestyle = '--')\n",
    "ax2.set_title(\"RF: %.2f\" % roc_aucRF, size = 21, x = .485, ha = 'center')\n",
    "\n",
    "ax3.plot(fprKNN, tprKNN)\n",
    "ax3.plot([0, 1], [0, 1], linestyle = '--')\n",
    "ax3.set_title(\"KNN: %.2f\" % roc_aucKNN, size = 21, x = .485, ha = 'center')\n",
    "\n",
    "ax4.plot(fprDNN, tprDNN)\n",
    "ax4.plot([0, 1], [0, 1], linestyle = '--')\n",
    "ax4.set_title(\"DNN: %.2f\" % roc_aucDNN, size = 21, x = .485, ha = 'center')\n",
    "\n",
    "rocHOF.legend(loc = (.25, .87), ncol=2, prop={'size': 12, \"family\": \"Rockwell\"})\n",
    "rocHOF.text(-0.03, 0.5, \"True positive rate\", va='center', rotation='vertical', size = 18)\n",
    "rocHOF.text(0.5, -0.04, \"False positive rate\", ha = 'center', size = 18)\n",
    "\n",
    "rocHOF.suptitle(\"http://dribbleanalytics.blogspot.com\", y = 1.13, fontname = 'Rockwell', size = 14)\n",
    "\n",
    "rocHOF.savefig('roc-hof.png', dpi = 400, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict rookies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svcPred = svc.predict(rookieTest)\n",
    "\n",
    "for i, j in zip(svcPred, rookieNames):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfPred = rf.predict(rookieTest)\n",
    "\n",
    "for i, j in zip(rfPred, rookieNames):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnPred = knn.predict(rookieTest)\n",
    "\n",
    "for i, j in zip(knnPred, rookieNames):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnnPred = dnn.predict(rookieTest)\n",
    "\n",
    "for i, j in zip(dnnPred, rookieNames):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data splits for All Star models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(dfHistorical, test_size = 0.25, random_state = 0)\n",
    "\n",
    "xtrain = train[['G', 'MPG', 'FG/G', 'FGA/G', '2P%', '3P%', 'FT%', 'TRB/G', 'AST/G', 'STL/G', 'BLK/G', 'TOV/G', 'PF/G',\n",
    "                'TS%', '3PAr', 'FTr']]\n",
    "ytrain = train[['All Star']]\n",
    " \n",
    "xtest = test[['G', 'MPG', 'FG/G', 'FGA/G', '2P%', '3P%', 'FT%', 'TRB/G', 'AST/G', 'STL/G', 'BLK/G', 'TOV/G', 'PF/G',\n",
    "              'TS%', '3PAr', 'FTr']]\n",
    "ytest = test[['All Star']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create models and confusion matrices for All Star models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel='rbf', gamma=1e-4, C=100, probability = True)\n",
    "svc.fit(xtrain, ytrain.values.ravel())\n",
    "\n",
    "y_svc = svc.predict(xtest)\n",
    "\n",
    "print(\"Accuracy score: %.3f\" % metrics.accuracy_score(ytest, y_svc))\n",
    "\n",
    "proba = svc.predict_proba(xtest)\n",
    "print(\"Log loss: %.3f\" % metrics.log_loss(ytest, proba))\n",
    "\n",
    "posProb = proba[:, 1]\n",
    "print(\"Area under ROC curve: %.3f\" % metrics.roc_auc_score(ytest, posProb))\n",
    "\n",
    "fprSVC, tprSVC, thresholdSVC = metrics.roc_curve(ytest, posProb)\n",
    "roc_aucSVC = metrics.auc(fprSVC, tprSVC)\n",
    "\n",
    "cvScoreSVC = cross_val_score(svc, xtest, ytest.values.ravel(), cv = 3, scoring = 'accuracy')\n",
    "print(\"Accuracy (cross validation score): %0.2f (+/- %0.2f)\" % (cvScoreSVC.mean(), cvScoreSVC.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(ytest, y_svc)\n",
    "\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "svcHofAS, ax = plt.subplots()\n",
    "\n",
    "sns.heatmap(cm, annot=True, ax = ax, linewidth = 2)\n",
    "\n",
    "ax.set_xlabel(\"Predicted\")\n",
    "ax.set_ylabel(\"Actual\")\n",
    "\n",
    "labels = [\"Not All Star\", \"All Star\"]\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_yticklabels(labels)\n",
    "\n",
    "svcHofAS.suptitle(\"SVC Confusion Matrix\", weight = 'bold', size = 18, y = 1.04, x = .45)\n",
    "ax.set_title(\"http://dribbleanalytics.blogspot.com\", size = 14, fontname = 'Rockwell', y = 1.02)\n",
    "\n",
    "svcHofAS.savefig('svc-hof-as.png', dpi = 400, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state = 999, n_estimators = 200, criterion = 'gini')\n",
    "rfPred = rf.fit(xtrain, ytrain.values.ravel())\n",
    "y_rf = rfPred.predict(xtest)\n",
    "\n",
    "print(\"Accuracy score: %.3f\" % metrics.accuracy_score(ytest, y_rf))\n",
    "\n",
    "proba = rf.predict_proba(xtest)\n",
    "print(\"Log loss: %.3f\" % metrics.log_loss(ytest, proba))\n",
    "\n",
    "posProb = proba[:, 1]\n",
    "print(\"Area under ROC curve: %.3f\" % metrics.roc_auc_score(ytest, posProb))\n",
    "\n",
    "fprRF, tprRF, thresholdRF = metrics.roc_curve(ytest, posProb)\n",
    "roc_aucRF = metrics.auc(fprRF, tprRF)\n",
    "\n",
    "cvScoreRF = cross_val_score(rf, xtest, ytest.values.ravel(), cv = 3, scoring = 'accuracy')\n",
    "print(\"Accuracy (cross validation score): %0.2f (+/- %0.2f)\" % (cvScoreRF.mean(), cvScoreRF.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(ytest, y_rf)\n",
    "\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "rfHofAS, ax = plt.subplots()\n",
    "\n",
    "sns.heatmap(cm, annot=True, ax = ax, linewidth = 2)\n",
    "\n",
    "ax.set_xlabel(\"Predicted\")\n",
    "ax.set_ylabel(\"Actual\")\n",
    "\n",
    "labels = [\"Not All Star\", \"All Star\"]\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_yticklabels(labels)\n",
    "\n",
    "rfHofAS.suptitle(\"RF Confusion Matrix\", weight = 'bold', size = 18, y = 1.04, x = .45)\n",
    "ax.set_title(\"http://dribbleanalytics.blogspot.com\", size = 14, fontname = 'Rockwell', y = 1.02)\n",
    "\n",
    "rfHofAS.savefig('rf-hof-as.png', dpi = 400, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors = 7, weights = 'uniform')\n",
    "knn.fit(xtrain, ytrain.values.ravel())\n",
    "\n",
    "y_knn = knn.predict(xtest)\n",
    "\n",
    "print(\"Accuracy score: %.3f\" % metrics.accuracy_score(ytest, y_knn))\n",
    "\n",
    "proba = knn.predict_proba(xtest)\n",
    "print(\"Log loss: %.3f\" % metrics.log_loss(ytest, proba))\n",
    "\n",
    "posProb = proba[:, 1]\n",
    "print(\"Area under ROC curve: %.3f\" % metrics.roc_auc_score(ytest, posProb))\n",
    "\n",
    "fprKNN, tprKNN, thresholdKNN = metrics.roc_curve(ytest, posProb)\n",
    "roc_aucKNN = metrics.auc(fprKNN, tprKNN)\n",
    "\n",
    "cvScoreKNN = cross_val_score(knn, xtest, ytest.values.ravel(), cv = 3, scoring = 'accuracy')\n",
    "print(\"Accuracy (cross validation score): %0.2f (+/- %0.2f)\" % (cvScoreKNN.mean(), cvScoreKNN.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(ytest, y_knn)\n",
    "\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "knnHofAS, ax = plt.subplots()\n",
    "\n",
    "sns.heatmap(cm, annot=True, ax = ax, linewidth = 2)\n",
    "\n",
    "ax.set_xlabel(\"Predicted\")\n",
    "ax.set_ylabel(\"Actual\")\n",
    "\n",
    "labels = [\"Not All Star\", \"All Star\"]\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_yticklabels(labels)\n",
    "\n",
    "knnHofAS.suptitle(\"KNN Confusion Matrix\", weight = 'bold', size = 18, y = 1.04, x = .45)\n",
    "ax.set_title(\"http://dribbleanalytics.blogspot.com\", size = 14, fontname = 'Rockwell', y = 1.02)\n",
    "\n",
    "knnHofAS.savefig('knn-hof-as.png', dpi = 400, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn = MLPClassifier(\n",
    "    solver='lbfgs',\n",
    "    hidden_layer_sizes=100,\n",
    "    max_iter=10000,\n",
    "    shuffle=False,\n",
    "    random_state=0,\n",
    "    activation='identity')\n",
    "\n",
    "dnn.fit(xtrain, ytrain.values.ravel())\n",
    "\n",
    "y_dnn = dnn.predict(xtest)\n",
    "\n",
    "print(\"Accuracy score: %.3f\" % metrics.accuracy_score(ytest, y_dnn))\n",
    "\n",
    "proba = dnn.predict_proba(xtest)\n",
    "print(\"Log loss: %.3f\" % metrics.log_loss(ytest, proba))\n",
    "\n",
    "posProb = proba[:, 1]\n",
    "print(\"Area under ROC curve: %.3f\" % metrics.roc_auc_score(ytest, posProb))\n",
    "\n",
    "fprDNN, tprDNN, thresholdDNN = metrics.roc_curve(ytest, posProb)\n",
    "roc_aucDNN = metrics.auc(fprDNN, tprDNN)\n",
    "\n",
    "cvScoreDNN = cross_val_score(dnn, xtest, ytest.values.ravel(), cv = 3, scoring = 'accuracy')\n",
    "print(\"Accuracy (cross validation score): %0.2f (+/- %0.2f)\" % (cvScoreDNN.mean(), cvScoreDNN.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(ytest, y_dnn)\n",
    "\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "dnnHofAS, ax = plt.subplots()\n",
    "\n",
    "sns.heatmap(cm, annot=True, ax = ax, linewidth = 2)\n",
    "\n",
    "ax.set_xlabel(\"Predicted\")\n",
    "ax.set_ylabel(\"Actual\")\n",
    "\n",
    "labels = [\"Not All Star\", \"All Star\"]\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_yticklabels(labels)\n",
    "\n",
    "dnnHofAS.suptitle(\"DNN Confusion Matrix\", weight = 'bold', size = 18, y = 1.04, x = .45)\n",
    "ax.set_title(\"http://dribbleanalytics.blogspot.com\", size = 14, fontname = 'Rockwell', y = 1.02)\n",
    "\n",
    "dnnHofAS.savefig('dnn-hof-as.png', dpi = 400, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomized search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC\n",
    "\n",
    "C = [int(x) for x in np.linspace(start = 1, stop = 100, num = 10)]\n",
    "\n",
    "kernel = ['rbf', 'linear']\n",
    "\n",
    "gamma = [float(x) for x in np.linspace(start = 1e-5, stop = 10, num = 10)]\n",
    "\n",
    "random_grid = {'C': C,\n",
    "               'kernel': kernel,\n",
    "               'gamma': gamma}\n",
    "\n",
    "svc_random = RandomizedSearchCV(estimator = svc, param_distributions = random_grid, n_iter = 25, cv = 3, \n",
    "                                verbose=2, random_state=42, n_jobs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_random.fit(xtrain, ytrain.values.ravel())\n",
    "\n",
    "y_svcrand = svc_random.predict(xtest)\n",
    "\n",
    "searchScore = metrics.accuracy_score(ytest, y_svcrand)\n",
    "nonSearchScore = metrics.accuracy_score(ytest, y_svc)\n",
    "improvement = (searchScore - nonSearchScore) / nonSearchScore\n",
    "\n",
    "print(\"Percent improvement: %.5f\" % improvement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 500, num = 10)]\n",
    "\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "bootstrap = [True, False]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 25, cv = 3, \n",
    "                               verbose=2, random_state=42, n_jobs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.fit(xtrain, ytrain.values.ravel())\n",
    "\n",
    "y_rfrand = rf_random.predict(xtest)\n",
    "\n",
    "searchScore = metrics.accuracy_score(ytest, y_rfrand)\n",
    "nonSearchScore = metrics.accuracy_score(ytest, y_rf)\n",
    "improvement = (searchScore - nonSearchScore) / nonSearchScore\n",
    "\n",
    "print(\"Percent improvement: %.5f\" % improvement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "\n",
    "n_neighbors = [int(x) for x in np.linspace(1, 50, num = 10)]\n",
    "\n",
    "weights = ['distance', 'uniform']\n",
    "\n",
    "random_grid = {'n_neighbors': n_neighbors,\n",
    "               'weights': weights}\n",
    "\n",
    "knn_random = RandomizedSearchCV(estimator = knn, param_distributions = random_grid, n_iter = 25, cv = 3, \n",
    "                               verbose=2, random_state=42, n_jobs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_random.fit(xtrain, ytrain.values.ravel())\n",
    "\n",
    "y_knnrand = knn_random.predict(xtest)\n",
    "\n",
    "searchScore = metrics.accuracy_score(ytest, y_knnrand)\n",
    "nonSearchScore = metrics.accuracy_score(ytest, y_knn)\n",
    "improvement = (searchScore - nonSearchScore) / nonSearchScore\n",
    "\n",
    "print(\"Percent improvement: %.5f\" % improvement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNN\n",
    "\n",
    "hidden_layers = [int(x) for x in np.linspace(start = 10, stop = 500, num = 10)]\n",
    "\n",
    "activation = ['identity', 'logistic', 'relu', 'tanh']\n",
    "\n",
    "solver = ['lbfgs', 'adam', 'sgd']\n",
    "\n",
    "random_grid = {'hidden_layers': hidden_layers,\n",
    "               'activation': activation,\n",
    "               'solver': solver}\n",
    "\n",
    "dnn_random = RandomizedSearchCV(estimator = dnn, param_distributions = random_grid, n_iter = 25, cv = 3, \n",
    "                               verbose=2, random_state=42, n_jobs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_random.fit(xtrain, ytrain.values.ravel())\n",
    "\n",
    "y_dnnrand = dnn_random.predict(xtest)\n",
    "\n",
    "searchScore = metrics.accuracy_score(ytest, y_dnnrand)\n",
    "nonSearchScore = metrics.accuracy_score(ytest, y_dnn)\n",
    "improvement = (searchScore - nonSearchScore) / nonSearchScore\n",
    "\n",
    "print(\"Percent improvement: %.5f\" % improvement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC curves for All Star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "rocAS, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, sharey = True, sharex = True)\n",
    "\n",
    "ax1.plot(fprSVC, tprSVC, label = 'ROC curve')\n",
    "ax1.plot([0, 1], [0, 1], linestyle = '--', label = 'Reference line')\n",
    "ax1.set_title(\"SVC: %.2f\" % roc_aucSVC, size = 21, x = .485, ha = 'center')\n",
    "\n",
    "ax2.plot(fprRF, tprRF)\n",
    "ax2.plot([0, 1], [0, 1], linestyle = '--')\n",
    "ax2.set_title(\"RF: %.2f\" % roc_aucRF, size = 21, x = .485, ha = 'center')\n",
    "\n",
    "ax3.plot(fprKNN, tprKNN)\n",
    "ax3.plot([0, 1], [0, 1], linestyle = '--')\n",
    "ax3.set_title(\"KNN: %.2f\" % roc_aucKNN, size = 21, x = .485, ha = 'center')\n",
    "\n",
    "ax4.plot(fprDNN, tprDNN)\n",
    "ax4.plot([0, 1], [0, 1], linestyle = '--')\n",
    "ax4.set_title(\"DNN: %.2f\" % roc_aucDNN, size = 21, x = .485, ha = 'center')\n",
    "\n",
    "rocAS.legend(loc = (.25, .87), ncol=2, prop={'size': 12, \"family\": \"Rockwell\"})\n",
    "rocAS.text(-0.03, 0.5, \"True positive rate\", va='center', rotation='vertical', size = 18)\n",
    "rocAS.text(0.5, -0.04, \"False positive rate\", ha = 'center', size = 18)\n",
    "\n",
    "rocAS.suptitle(\"http://dribbleanalytics.blogspot.com\", y = 1.13, fontname = 'Rockwell', size = 14)\n",
    "\n",
    "rocAS.savefig('roc-as.png', dpi = 400, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict rookies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svcPred = svc.predict(rookieTest)\n",
    "\n",
    "for i, j in zip(svcPred, rookieNames):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfPred = rf.predict(rookieTest)\n",
    "\n",
    "for i, j in zip(rfPred, rookieNames):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnPred = knn.predict(rookieTest)\n",
    "\n",
    "for i, j in zip(knnPred, rookieNames):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnnPred = dnn.predict(rookieTest)\n",
    "\n",
    "for i, j in zip(dnnPred, rookieNames):\n",
    "    print(i, j)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
